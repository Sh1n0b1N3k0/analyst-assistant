# Database
# Вариант 1: Supabase локально через Docker (рекомендуется для разработки)
USE_SUPABASE=true
SUPABASE_URL=http://localhost:8000
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU
SUPABASE_DB_URL=postgresql://postgres:your-super-secret-jwt-token-with-at-least-32-characters-long@localhost:5432/postgres

# Вариант 2: Supabase в облаке
# USE_SUPABASE=true
# SUPABASE_URL=https://your-project.supabase.co
# SUPABASE_KEY=your_supabase_anon_key
# SUPABASE_SERVICE_KEY=your_supabase_service_role_key
# SUPABASE_DB_URL=postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres

# Вариант 3: Прямой PostgreSQL (если не используете Supabase)
# USE_SUPABASE=false
# DATABASE_URL=postgresql://postgres:postgres@localhost:5432/requirements_db

# Neo4j (локально через Docker)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Для Docker Compose используйте:
# NEO4J_URI=bolt://neo4j:7687

# ============================================
# AI Configuration
# ============================================

# Базовый провайдер по умолчанию для всех агентов
AI_PROVIDER=openai

# OpenAI (базовый провайдер)
OPENAI_API_KEY=your_openai_api_key_here
AI_OPENAI_MODEL=gpt-4-turbo-preview
AI_OPENAI_TEMPERATURE=0.7

# Anthropic (опционально)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
AI_ANTHROPIC_MODEL=claude-3-opus-20240229
AI_ANTHROPIC_TEMPERATURE=0.7

# Azure OpenAI (опционально)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AI_AZURE_OPENAI_MODEL=gpt-4
AI_AZURE_OPENAI_TEMPERATURE=0.7

# OpenRouter (опционально)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
AI_OPENROUTER_MODEL=openai/gpt-4-turbo
AI_OPENROUTER_TEMPERATURE=0.7

# Ollama (опционально, локальный)
AI_OLLAMA_BASE_URL=http://localhost:11434
AI_OLLAMA_MODEL=llama2
AI_OLLAMA_TEMPERATURE=0.7

# ============================================
# Agent-specific configurations
# Можно переопределить провайдер, модель, API ключ и температуру для каждого агента
# ============================================

# Администратор проекта
AI_PROJECT_ADMIN_PROVIDER=
AI_PROJECT_ADMIN_MODEL=
AI_PROJECT_ADMIN_API_KEY=
AI_PROJECT_ADMIN_TEMPERATURE=

# Обработчик входящих требований
AI_REQUIREMENT_PROCESSOR_PROVIDER=
AI_REQUIREMENT_PROCESSOR_MODEL=
AI_REQUIREMENT_PROCESSOR_API_KEY=
AI_REQUIREMENT_PROCESSOR_TEMPERATURE=

# База знаний требований
AI_KNOWLEDGE_BASE_PROVIDER=
AI_KNOWLEDGE_BASE_MODEL=
AI_KNOWLEDGE_BASE_API_KEY=
AI_KNOWLEDGE_BASE_TEMPERATURE=

# Генератор спецификаций
AI_SPEC_GENERATOR_PROVIDER=
AI_SPEC_GENERATOR_MODEL=
AI_SPEC_GENERATOR_API_KEY=
AI_SPEC_GENERATOR_TEMPERATURE=

# ============================================
# Security Configuration
# ============================================
SECRET_KEY=your-secret-key-change-in-production-min-32-chars
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_REQUESTS_PER_HOUR=1000

